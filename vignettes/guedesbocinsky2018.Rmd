---
title: "Title Goes Here"
author:
  - R. Kyle Bocinsky
  - Jade d'Alpoim Guedes
date: "`r format(Sys.time(), '%d %B, %Y')`"
params:
   cores: 2
   clean: FALSE
output: 
    bookdown::html_document2:
      df_print: paged
      fig_caption: yes
      toc: yes
      toc_depth: 3
      toc_float:
        collapsed: no
bibliography: references.bib
csl: "./templates/science.csl" # Insert path for the bib-style
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---


<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

```{r, setup, echo = FALSE, cache = FALSE}
# params <- list(cores = 2,
#                clean = FALSE)

# Set the knitting behavior
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      collapse = TRUE, 
                      cache = !params$clean,
                      results = 'hold',
                      out.width = "100%",
                      fig.height = 5,  
                      comment = "#>",
                      fig.path = "./figures/"
)

library(guedesbocinsky2018)
library(sf)
library(magrittr)
library(foreach)
library(doParallel)

# Set the behavior for printing scientific notation
# options(digits = 3, scipen = -2)
options(scipen = 999)

# Force Raster to load large rasters into memory
raster::rasterOptions(chunksize=2e+08,maxmemory=2e+09)

```

## Set parameters

```{r set-params}
# A function to set an objects class
set_class <- function(x, classes){
  class(x) <- classes
  return(x)
}

#Define the study region
ASIA_poly <-
  raster::extent(55,125,5,60) %>% ## THE REAL EURASIAN POLYGON
  # raster::extent(66,72,37,43) %>% ## FOR TESTING PURPOSES ONLY
  FedData::polygon_from_extent("+proj=longlat") %>%
  sf::st_as_sf()

# Set the calibration period for paleoclimate reconstructions
calibration.years <- 1961:1990

# Set this to your google maps elevation api key
# https://developers.google.com/maps/documentation/elevation/start
google_maps_elevation_api_key = "AIzaSyDi4YVDZPt6uH1C1vF8YRpbp1mxqsWbi5M"

# A ggplot2 theme for Nature Publishing Group
nature_theme <- ggplot2::theme(panel.grid.major = ggplot2::element_line(size = 0.5, color = "grey"),
                               axis.line = ggplot2::element_line(size = 0.7, color = "black"),
                               legend.position = c(0.85, 0.7),
                               text = ggplot2::element_text(size = 14))
```

## Load ETOPO5 grids
```{r etopo5}
message("Preparing the ETOPO5 grid-aligned dataset")

time_check <-  Sys.time()

if(!params$clean & file.exists("./data/derived_data/ASIA_rast_etopo5.tif")){
  
  ASIA_rast_etopo5 <- raster::raster("./data/derived_data/ASIA_rast_etopo5.tif")
  
}else{
  
  # Get the Natural Earth country lakes data
  dir.create("./data/derived_data/NaturalEarth/", 
             showWarnings = FALSE, 
             recursive = TRUE)
  
  FedData::download_data(
    url = "http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/physical/ne_10m_lakes.zip",
    destdir = "./data/derived_data/NaturalEarth/"
  )
  
  unzip(
    "./data/derived_data/NaturalEarth/ne_10m_lakes.zip", 
    exdir = "./data/derived_data/NaturalEarth/ne_10m_lakes/"
  )
  
  ne_10m_lakes <- "./data/derived_data/NaturalEarth/ne_10m_lakes/ne_10m_lakes.shp" %>%
    sf::st_read() %>%
    sf::st_transform(sf::st_crs(ASIA_poly)) %>%
    sf::st_intersection(ASIA_poly)
  
  # Get the Natural Earth country boundaries data
  dir.create(
    "./data/derived_data/NaturalEarth/ne_10m_admin_0_countries_lakes/",
    showWarnings = FALSE, 
    recursive = TRUE
  )
  FedData::download_data(
    url = "http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries_lakes.zip",
    destdir = "./data/derived_data/NaturalEarth/"
  )
  
  unzip(
    "./data/derived_data/NaturalEarth/ne_10m_admin_0_countries_lakes.zip", 
    exdir = "./data/derived_data/NaturalEarth/ne_10m_admin_0_countries_lakes/"
  )
  
  ne_10m_admin_0_countries_lakes <- "./data/derived_data/NaturalEarth/ne_10m_admin_0_countries_lakes/ne_10m_admin_0_countries_lakes.shp" %>%
    sf::st_read() %>%
    sf::st_transform(sf::st_crs(ASIA_poly)) %>%
    sf::st_intersection(ASIA_poly) %>%
    dplyr::filter(!(NAME %in% c("Indonesia",
                                "Scarborough Reef",
                                "Malaysia",
                                "Philippines",
                                "Maldives",
                                "Spratly Is.",
                                "Oman",
                                "United Arab Emirates",
                                "Saudi Arabia")))
  
  library(geomapdata)
  data("ETOPO5")
  
  ASIA_rast_etopo5 <- ETOPO5 %>%
    t() %>%
    raster::raster(xmn = 0,
                   xmx = 360,
                   ymn = -90,
                   ymx = 90,
                   crs = sp::CRS("+proj=longlat +ellps=clrk66 +no_defs")) %>%
    raster::crop(ASIA_poly %>%
                   sf::st_transform("+proj=longlat +ellps=clrk66 +no_defs") %>%
                   as("Spatial")) %>%
    raster::mask(ne_10m_admin_0_countries_lakes %>%
                   sf::st_transform("+proj=longlat +ellps=clrk66 +no_defs") %>%
                   as("Spatial")) %>%
    raster::mask(ne_10m_lakes %>%
                   sf::st_transform("+proj=longlat +ellps=clrk66 +no_defs") %>%
                   as("Spatial"),
                 inverse = TRUE) %T>%
    raster::writeRaster(filename = "./data/derived_data/ASIA_rast_etopo5.tif",
                        datatype="INT2S",
                        options=c("COMPRESS=DEFLATE", "ZLEVEL=9", "INTERLEAVE=BAND", "PHOTOMETRIC=MINISWHITE"),
                        overwrite=T,
                        setStatistics=FALSE)
  rm(ETOPO5)
}

countries <- "./data/derived_data/NaturalEarth/ne_10m_admin_0_countries_lakes/ne_10m_admin_0_countries_lakes.shp" %>%
  sf::st_read()  %>%
  sf::st_transform(sf::st_crs(ASIA_poly)) %>%
  sf::st_intersection(ASIA_poly) %>%
  dplyr::filter(!(NAME %in% c("Indonesia",
                              "Scarborough Reef",
                              "Malaysia",
                              "Philippines",
                              "Maldives",
                              "Spratly Is.",
                              "Oman",
                              "United Arab Emirates",
                              "Saudi Arabia"))) %>%
  dplyr::select(NAME, geometry)

message("ETOPO5 grid-aligned dataset preparation complete: ", capture.output(Sys.time() - time_check))

```

## Prepare the GHCN data
```{r ghcn}
## Downloads and cleans daily climate records from the Global Historical Climate Database.
message("Preparing the daily climate records from the Global Historical Climate Database")
time_check <-  Sys.time()
GHCN.data.final <- prepare_ghcn(region = ASIA_poly %>%
                                  as("Spatial"),
                                label = "ASIA_poly",
                                calibration.years = calibration.years,
                                google_maps_elevation_api_key = google_maps_elevation_api_key,
                                raw_dir = "./data/raw_data/ghcn/",
                                derived_dir = "./data/derived_data/ghcn/",
                                force.redo = params$clean)
message("GHCN preparation complete: ", capture.output(Sys.time() - time_check))
## An example of plotting the GHCN data
# climate_plotter(data = GHCN.data.final, station = "CHM00051334", element = "TMIN")

```

## Prepare the Marcott data
```{r marcott}
# Run the script that transforms the Marcott et al. 2013 data into standard scores.
message("Preparing the Marcott et al. 2013 data")
time_check <-  Sys.time()
marcott2013 <- prepare_marcott(calibration.years = calibration.years)
message("Marcott et al. 2013 data preparation complete: ", capture.output(Sys.time() - time_check))

```

## Modulating climatology by SD
```{r sd-modulation}
#### Calculating growing degree days ####
message("Modulating local climatology by Marcott et al. 2013 data")
time_check <-  Sys.time()
# How often to sample GDD, in z-space, for model tuning
# Here, we sample from -20 to 20 SD, at 1 SD interval
sample.points <- -20:20

# Read in data on different crop GDD needs
crop_GDD <- readr::read_csv("./data/raw_data/crops.csv",
                            col_types = readr::cols(
                              cultivar_long = readr::col_character(),
                              cultivar = readr::col_character(),
                              crop_long = readr::col_character(),
                              crop = readr::col_character(),
                              t_base = readr::col_double(),
                              min_gdd = readr::col_integer()
                            )) #%>%
# dplyr::filter(crop %in% c("foxtail_millet",
#                           "broomcorn_millet",
#                           "wheat",
#                           "barley",
#                           "buckwheat"))

# create the cluster for parallel computation
library(doParallel)
cl <- parallel::makeCluster(params$cores, type = "PSOCK")
doParallel::registerDoParallel(cl)

# Transform GHCN data to GDDs of each base, and modulate to Marcott
GDDs <- sort(unique(crop_GDD$t_base))

GHCN.GDD.incremented.sd <- 
  foreach::foreach(base = GDDs,
                   .packages = c("foreach",
                                 "magrittr",
                                 "guedesbocinsky2018")) %dopar% {
                                   
                                   out <- 
                                     purrr::map_dfr(sample.points,
                                                    function(change){
                                                      
                                                      
                                                      GHCN.GDDs <- 
                                                        purrr::map_dbl(GHCN.data.final$climatology,
                                                                       function(station){
                                                                         return(sdModulator(data.df = station,
                                                                                            temp.change.sd = change,
                                                                                            t.base = base,
                                                                                            t.cap = 30))
                                                                       })
                                                      
                                                      
                                                      names(GHCN.GDDs) <- names(GHCN.data.final$climatology)
                                                      
                                                      return(tibble::tibble(SD_change = change,
                                                                            ID = names(GHCN.GDDs),
                                                                            GDD = GHCN.GDDs))
                                                      
                                                    })
                                   
                                   
                                   return(out %>%
                                            dplyr::left_join(GHCN.data.final$spatial %>%
                                                               dplyr::as_data_frame() %>%
                                                               # dplyr::rename(LONGITUDE = coords.x1,
                                                               #               LATITUDE = coords.x2) %>%
                                                               dplyr::rename(x = LONGITUDE, 
                                                                             y = LATITUDE), 
                                                             by = "ID"))
                                 }

names(GHCN.GDD.incremented.sd) <- GDDs

# stop the cluster (will free memory)
stopCluster(cl)
message("Modulation of local climatology by Marcott et al. 2013 data complete: ", capture.output(Sys.time() - time_check))

```

## Generate the crop niche models
```{r generate-niche-models}
message("Calculating indicator Krige models")
time_check <-  Sys.time()
# Create a spatialPointsDataFrame of the etopo5 data, and convert to WGS84 ellipsoid
ASIA_rast_etopo5.sp <-
  ASIA_rast_etopo5 %>%
  magrittr::set_names("elevation") %>%
  raster::rasterToPoints(spatial = T) %>%
  sp::spTransform(sp::CRS(raster::projection(GHCN.data.final$spatial)))

# A function that generates the kriging model, then predicts
krige_and_predict <- function(dt){
  model <- fields::mKrig(x = dt[,c("x","y")],
                         y = dt$GDD_thresh,
                         Z = dt$elevation,
                         Covariance = "Exponential",
                         Distance = "rdist.earth")
  
  prediction <- ASIA_rast_etopo5.sp %>%
    tibble::as_tibble() %>%
    dplyr::mutate(chunk = rep(1:ceiling(nrow(.)/chunk_size),length.out = nrow(.)) %>%
                    sort()
    ) %>%
    dplyr::group_by(chunk) %>%
    dplyr::do(prediction = fields::predict.mKrig(model,
                                                 xnew = .[,c("x","y")],
                                                 Z = .$elevation) %>%
                as.vector()) %$%
    prediction %>%
    unlist()
  
  return(list(model = model, prediction = prediction))
  
}

# Calculate gdd kriging models for each crop
gdd_model_files <- paste0("./data/derived_data/models/",crop_GDD$cultivar,"_models.rds")

if(params$clean){
  unlink("./data/derived_data/models/", recursive = TRUE, force = TRUE)
  dir.create("./data/derived_data/models/", recursive = TRUE, showWarnings = F)
  crop_GDD_run <- crop_GDD
}else{
  dir.create("./data/derived_data/models/", recursive = TRUE, showWarnings = F)
  crop_GDD_run <- crop_GDD[!file.exists(gdd_model_files),]
}

if(nrow(crop_GDD_run) == 0){
  message("All indicator Krige models have already been calculated. Continuing.")
}else message("Calculating indicator Krige models for ",
              nrow(crop_GDD_run),
              " cultivars:\n",
              paste0(capture.output(crop_GDD_run), collapse = "\n"))

# A function to reduce the size of a loess model by half
skinny.loess <- function(x){
  x[c("fitted",
      "residuals",
      "enp",
      "one.delta",
      "two.delta",
      "trace.hat",
      "call",
      "terms",
      "xnames")] <- NULL
  return(x)
}

# A function of correct the indication predictions and estimate a smooth
# monotonic function
# This first uses isotonic regression, then loess smoothing with a degree of 1
smooth.preds <- function(y){
  y[y<0] <- 0
  y[y>1] <- 1
  y <- loess(isoreg(y~sample.points)$yf~sample.points, span=0.1, degree=1) %>%
    skinny.loess()
  return(y)
}

if(nrow(crop_GDD_run) > 0){
  # create the cluster for parallel computation
  cl <- makeCluster(min(params$cores,nrow(crop_GDD_run)), type = "PSOCK")
  registerDoParallel(cl)
  
  options(dplyr.show_progress = FALSE)
  chunk_size <- 10000
  
  gdd.models <- foreach::foreach(crop = 1:nrow(crop_GDD_run),
                                 .packages = c("fields",
                                               "dplyr",
                                               "magrittr",
                                               "foreach",
                                               "doParallel",
                                               "readr",
                                               "guedesbocinsky2018"),
                                 .export = c("sample.points")) %dopar% {
                                   
                                   # Threshold for indicator kriging
                                   GHCN.GDD.incremented.sd[[as.character(crop_GDD_run[crop,"t_base"])]] %>%
                                     dplyr::mutate(GDD_thresh = {GDD >= as.numeric(crop_GDD_run[crop,"min_gdd"])}) %>%
                                     dplyr::group_by(SD_change) %>%
                                     dplyr::do(out_preds = krige_and_predict(.)) %$%
                                     out_preds %>%
                                     sapply("[[","prediction") %>%
                                     apply(1,smooth.preds) %>%
                                     tibble::tibble(model = .) %>%
                                     maptools::spCbind(ASIA_rast_etopo5.sp,.) %>%
                                     readr::write_rds(paste0("./data/derived_data/models/",
                                                             crop_GDD_run[crop,"cultivar"],
                                                             "_models.rds"), 
                                                      compress = "xz")
                                   
                                   return(paste0("./data/derived_data/models/",
                                                 crop_GDD_run[crop,"cultivar"],
                                                 "_models.rds"))
                                 }
  
  # stop the cluster (will free memory)
  stopCluster(cl)
  
}

rm(ASIA_rast_etopo5,
   ASIA_rast_etopo5.sp,
   GHCN.data.final,
   GHCN.GDD.incremented.sd)

message("Calculation indicator Krige models complete: ", capture.output(Sys.time() - time_check))

```

## Predict crop niches through time
```{r predict-niches}
## Predicting crop niche from smoothed Krige models
# Calculate niches for each crop using the Marcott et al. 2013.
# create the cluster for parallel computation
message("Generating niche reconstructions")
time_check <-  Sys.time()
if(params$clean){
  unlink("./data/derived_data/recons/", recursive = TRUE, force = TRUE)
}
dir.create("./data/derived_data/recons/", recursive = TRUE, showWarnings = F)

purrr::walk(crop_GDD$cultivar, 
            function(crop){
              
              if(!file.exists(paste0("./data/derived_data/models/",
                                     crop,
                                     "_models.rds"))) 
                stop("Models for ",
                     crop,
                     " are missing! Aborting.")
              
              Zs <- c("Z_Lower","Z","Z_Upper")
              Zs %<>%
                magrittr::extract({
                  Zs %>%
                    paste0("./data/derived_data/recons/",
                           crop,
                           "_",.,".nc") %>%
                    file.exists() %>%
                    magrittr::not()
                })
              
              if(length(Zs)==0) return()
              
              crop.models <- readr::read_rds(paste0("./data/derived_data/models/",
                                                    crop,
                                                    "_models.rds"))
              
              purrr::walk(Zs, 
                          function(z){
                            suppressWarnings(
                              crop.models@data %$%
                                model %>%
                                purrr::map(
                                  function(x){
                                    x %>%
                                      predict(newdata = marcott2013[[z]]) %>%
                                      magrittr::multiply_by(100) %>%
                                      round()
                                  }) %>%
                                do.call(rbind, .) %>%
                                tibble::as_tibble() %>%
                                magrittr::set_colnames(marcott2013$YearBP) %>%
                                new("SpatialPointsDataFrame",
                                    data = .,
                                    coords.nrs = crop.models@coords.nrs,
                                    coords = crop.models@coords,
                                    bbox = crop.models@bbox,
                                    proj4string = crop.models@proj4string) %>%
                                as("SpatialPixelsDataFrame") %>%
                                raster::brick() %>%
                                raster::setZ(marcott2013$YearBP, 
                                             name="Years BP") %>%
                                raster::writeRaster(paste0("./data/derived_data/recons/",
                                                           crop,
                                                           "_",z,".nc"),
                                                    format = "CDF",
                                                    datatype = "INT2S",
                                                    varname = "niche_probability",
                                                    varunit = "unitless",
                                                    longname = "Probability of being in the crop niche x 100",
                                                    xname = "Longitude",
                                                    yname = "Latitude",
                                                    zname = "Years BP",
                                                    zunit = "Years BP",
                                                    overwrite = TRUE)
                              
                              
                            )
                          })
            })

message("Generation of niche reconstructions complete: ", capture.output(Sys.time() - time_check))

```

## Combine similar crop niches
```{r combine-niches}
## Combining crop niches from similar crops by taking an arithmatic mean
message("Combining like crop niches")
time_check <-  Sys.time()

combine_varieties <- function(x, file_tail){
  if(file.exists(paste0("./data/derived_data/recons/All_",x$crop[[1]],"_",file_tail,".nc"))) return(NULL)
  n_crops <- length(x$crop)
  purrr::map(x$cultivar, function(cultivar){
    paste0("./data/derived_data/recons/",cultivar,"_",file_tail,".nc") %>%
      raster::brick() %>%
      raster::getValues()
  }) %>%
    Reduce(f = "+", x = .) %>%
    magrittr::divide_by(n_crops) %>%
    round() %>%
    raster::setValues(raster::brick(paste0("./data/derived_data/recons/",x$cultivar[[1]],"_",file_tail,".nc")), .) %>%
    raster::writeRaster(paste0("./data/derived_data/recons/All_",x$crop[[1]],"_",file_tail,".nc"),
                        format = "CDF",
                        datatype = "INT2S",
                        varname = "niche_probability",
                        varunit = "unitless",
                        longname = "Probability of being in the crop niche x 100",
                        xname = "Longitude",
                        yname = "Latitude",
                        zname = "Years BP",
                        zunit = "Years BP",
                        # compression = 9,
                        overwrite = TRUE)
  return(NULL)
}

# create the cluster for parallel computation
# cl <- makeCluster(min(opt$cores,
#                       crop_GDD %$%
#                         crop %>%
#                         unique() %>%
#                         length()),
#                   type = "PSOCK")
# registerDoParallel(cl)
#
# # Get mean niche for Marcott predictions
# foreach::foreach(crop = crop_GDD %>%
#                    split(as.factor(crop_GDD$crop)),
#                  .packages = c("magrittr",
#                                "foreach"),
#                  .combine = c) %dopar% {
purrr::walk(crop_GDD %>%
              split(as.factor(crop_GDD$crop)),
            function(crop){
              combine_varieties(crop, file_tail = "Z") # Get mean niche for Marcott
              combine_varieties(crop, file_tail = "Z_Upper") # Get mean niche for Marcott upper CI
              combine_varieties(crop, file_tail = "Z_Lower") # Get mean niche for Marcott lower CI
            })

# stop the cluster (will free memory)
# stopCluster(cl)

message("Combining like crop niches complete: ", capture.output(Sys.time() - time_check))

```

```{r plot-niches-through-time, cache = FALSE}
## Plotting cultivar niche
# create the cluster for parallel computation
message("Plotting cultivar niche reconstructions")
time_check <-  Sys.time()

dir.create("./figures/cultivar_niches/",
           recursive = TRUE,
           showWarnings = FALSE)

gdd.recons <- foreach::foreach(n = 1:nrow(crop_GDD),
                               .combine = c) %do% {
                                 
                                 cultivar <- crop_GDD[n,]$cultivar
                                 
                                 title <- stringr::str_c(crop_GDD[n,]$cultivar_long,
                                                         " \u2014 T_base: ",
                                                         crop_GDD[n,]$t_base,
                                                         "°C, Required GDD: ",
                                                         crop_GDD[n,]$min_gdd)
                                 
                                 if(file.exists(paste0("./figures/cultivar_niches/",cultivar,".pdf")) & file.exists(paste0("./figures/cultivar_niches/",cultivar,".mp4")))
                                   return(paste0("./figures/cultivar_niches/",cultivar,".pdf"))
                                 
                                 rast <- raster::brick(paste0("./data/derived_data/recons/",cultivar,"_Z.nc")) %>%
                                   magrittr::extract2(which(.@z$`Years BP` > 1000)) %>%
                                   raster:::readAll() %>%
                                   magrittr::divide_by(100) %>%
                                   magrittr::extract2(raster::nlayers(.):1)
                                 
                                 rast.lower <- raster::brick(paste0("./data/derived_data/recons/",cultivar,"_Z_Lower.nc")) %>%
                                   magrittr::extract2(which(.@z$`Years BP` > 1000)) %>%
                                   raster:::readAll() %>%
                                   magrittr::divide_by(100) %>%
                                   magrittr::extract2(raster::nlayers(.):1)
                                 
                                 rast.upper <- raster::brick(paste0("./data/derived_data/recons/",cultivar,"_Z_Upper.nc")) %>%
                                   magrittr::extract2(which(.@z$`Years BP` > 1000)) %>%
                                   raster:::readAll() %>%
                                   magrittr::divide_by(100) %>%
                                   magrittr::extract2(raster::nlayers(.):1)
                                 
                                 years <- rast %>%
                                   names() %>%
                                   gsub(pattern = "X",
                                        replacement = "",
                                        x = .) %>%
                                   as.numeric()
                                 
                                 breaks <- seq(0, 1, 0.1)
                                 
                                 pal <- (RColorBrewer::brewer.pal(10, "Spectral") %>%
                                           rev() %>%
                                           colorRampPalette(.))(length(breaks) - 1)
                                 
                                 # pal <- c(rev(colorRampPalette(RColorBrewer::brewer.pal(9, "Blues")[2:9],
                                 #                               bias = 2,
                                 #                               space = "Lab")(76)),
                                 #          colorRampPalette(RColorBrewer::brewer.pal(9, "Reds")[2:9],
                                 #                           bias = 1.5,
                                 #                           space = "Lab")(26))
                                 
                                 if(!file.exists(paste0("./figures/cultivar_niches/",cultivar,".pdf")))
                                   guedesbocinsky2018:::space_time_plot(
                                     the_brick = rast,
                                     the_brick_lower = rast.lower,
                                     the_brick_upper = rast.upper,
                                     out_file = paste0("./figures/cultivar_niches/",cultivar,".pdf"),
                                     title = title,
                                     time = years,
                                     timelim = c(max(years),min(years)),
                                     timeaxis =  seq(from = max(years)-500,
                                                     to = min(years),
                                                     by = -500),
                                     timelab = "Years BP",
                                     zbreaks = breaks,
                                     zlab = "Probability of being in niche",
                                     zaxis = seq(0,1,0.1),
                                     zcolors = pal
                                   )
                                 
                                 if(!file.exists(paste0("./figures/cultivar_niches/",cultivar,".mp4")))
                                   guedesbocinsky2018:::space_time_video(the_brick = rast,
                                                                         the_brick_lower = rast.lower,
                                                                         the_brick_upper = rast.upper,
                                                                         out_file = paste0("./figures/cultivar_niches/",cultivar,".mp4"),
                                                                         title = title,
                                                                         time = years,
                                                                         timelim = c(max(years),min(years)),
                                                                         timeaxis =  seq(from = max(years)-500,
                                                                                         to = min(years),
                                                                                         by = -500),
                                                                         timelab = "Years BP",
                                                                         zbreaks = breaks,
                                                                         zlab = "Probability of being in niche",
                                                                         zaxis = seq(0,1,0.1),
                                                                         zcolors = pal
                                   )
                                 
                                 return(paste0("./figures/cultivar_niches/",cultivar,".pdf"))
                               }

message("Plotting of cultivar niche reconstructions complete: ", capture.output(Sys.time() - time_check))

```

## Chronometric analysis
```{r chronometric analysis}
message("Beginning chronometric co-analysis")

# Log in to tDAR
tdar::tdar_login()

# Read in the site/chronometric data
chronometric_data <- 
  tdar::tdar_download_resource(428089,
                               out_dir = "./data/raw_data/",
                               overwrite = FALSE) %>%
  readxl::read_excel(sheet = "chronometric_data",
                     col_types = c("text",
                                   "numeric",
                                   "numeric",
                                   "numeric",
                                   "logical",
                                   "text",
                                   "text",
                                   "text",
                                   "logical",
                                   "numeric",
                                   "numeric",
                                   "text",
                                   "numeric",
                                   "numeric",
                                   "text",
                                   rep("logical",18))
  ) %>%
  tibble::as_tibble() %>%
  dplyr::mutate(`Exclude?` = ifelse(is.na(`Exclude?`), FALSE, `Exclude?`)) %>%
  dplyr::filter(!is.na(Site),
                !is.na(Longitude),
                !is.na(Latitude),
                !(is.na(`14C age BP`) & is.na(`Age range lower (BP)`)),
                !is.na(`14C date on cereal?`),
                !`Exclude?`) %>%
  dplyr::select(-`Exclude?`, -Notes) %>%
  dplyr::group_by(Site,Period)

# Log out of tDAR
tdar::tdar_logout()

# Filter out sites not in study area
chronometric_names <- names(chronometric_data)
chronometric_data %<>%
  sf::st_as_sf(coords = c("Longitude", "Latitude"), remove = FALSE) %>%
  sf::st_set_crs("+proj=longlat") %>%
  sf::st_intersection(ASIA_poly %>%
                        sf::st_as_sf() %>%
                        sf::st_transform("+proj=longlat") %>%
                        sf::st_geometry()) %>%
  sf::st_intersection(countries %>%
                        sf::st_union() %>%
                        sf::st_transform("+proj=longlat")) %>%
  dplyr::as_data_frame() %>%
  dplyr::select(-geometry) %>%
  magrittr::set_names(chronometric_names)

# Write table of dates
chronometric_data %>%
  dplyr::mutate(`Estimated age range (BP)` = stringr::str_c(`Age range lower (BP)`,"–",`Age range upper (BP)`)) %>%
  dplyr::select(Site,
                Period,
                `Lab sample identifier`,
                Material,
                `14C age BP`,
                `1-sigma uncertainty`,
                `Estimated age range (BP)`,
                Reference) %>%
  # dplyr::filter(!is.na(`14C age BP`)) %>%
  dplyr::arrange(Site, Period) %>%
  readr::write_csv("./data/derived_data/sites_dates_raw.csv")

# Write some stats about the sites data used in this analysis
readr::write_lines(c("Sites data (after spatial and crop filtering)",
              paste0("Number of entries: ",
                     chronometric_data %>%
                       nrow()),
              paste0("Number of sites: ",
                     chronometric_data %$%
                       Site %>%
                       unique() %>%
                       length()),
              paste0("Number of distinct occupations: ",
                     chronometric_data %>%
                       dplyr::select(Site,Period) %>%
                       dplyr::distinct() %>%
                       nrow()),
              paste0("Number of radiocarbon dates: ",
                     chronometric_data %>%
                       dplyr::filter(!is.na(`14C age BP`)) %>%
                       nrow()),
              paste0("Number of radiocarbon sites: ",
                     chronometric_data %>%
                       dplyr::filter(!is.na(`14C age BP`)) %$%
                       Site %>%
                       unique() %>%
                       length())
),
"./data/derived_data/sites.txt")


# A function to calibrate either 14C dates (using BchronCalibrate), or
# site age estimates (using a flat density estimation)
calibrate_density <- function(x){
  if(!is.na(x$`14C age BP`)){
    out_calib <- Bchron::BchronCalibrate(ages = x$`14C age BP`,
                                         ageSds = x$`1-sigma uncertainty`,
                                         calCurves = 'intcal13') %>%
      magrittr::extract2(1)
    out_calib <- out_calib[c("ageGrid","densities")]
  } else {
    out_calib <- list()
    out_calib$ageGrid <- x$`Age range lower (BP)` : x$`Age range upper (BP)`
    out_calib$densities <- rep(1 / (x$`Age range lower (BP)` - x$`Age range upper (BP)`), length(out_calib$ageGrid))
  }
  return(out_calib)
}

# A function to extract density estimates over a vector of ages (years)
extract_density <- function(dens, vect){
  out_extract <- rep(0,length(vect))
  out_extract[which(vect %in% dens$ageGrid)] <- dens$densities[which(dens$ageGrid %in% vect)]
  return(out_extract)
}

densities <- chronometric_data %>%
  dplyr::select(Site,
                Period,
                `14C age BP`,
                `1-sigma uncertainty`,
                `Age range lower (BP)`,
                `Age range upper (BP)`) %>%
  purrrlyr::by_row(calibrate_density, # Generate probability densities for 14C dates and age ranges
                   .to = "Density") %>%
  dplyr::mutate(Prediction = purrr::map(Density, # Extract probabilities for Marcott years
                                        extract_density,
                                        vect = marcott2013$YearBP)) %>%
  dplyr::select(Site, Period, Prediction) %>%
  dplyr::group_by(Site, Period) %>%
  purrrlyr::by_slice(purrr::map,
                     ~ Reduce(x = .x, f = "+"), 
                     .to = "Density") %>% # Sum probabilities over sites and periods (as in Oxcal SUM command)
  dplyr::mutate(Density = purrr::map(Density, "Prediction"),
                Density = purrr::map(Density, ~ .x / sum(.x, na.rm = T))) # re-normalize to 1

# Filter out sites that don't have any occupation during the Marcott reconstruction
densities %<>%
  dplyr::filter(purrr::map_lgl(Density,
                               ~any(.x > 0)))

# Plot each site's probablility distribution
dir.create("./figures/site_densities/",
           recursive = TRUE,
           showWarnings = FALSE)
purrr::walk(unique(densities$Site), 
            function(site){
              if(!file.exists(paste0("./figures/site_densities/",site,".pdf"))){
                cairo_pdf(filename = paste0("./figures/site_densities/",site,".pdf"))
                g <- densities %>%
                  dplyr::filter(`Site` == site) %$%
                  Density %>%
                  magrittr::set_names(1:length(.)) %>%
                  tibble::as_tibble() %>%
                  dplyr::mutate(`Years BP` = marcott2013$YearBP) %>%
                  tidyr::gather(Period, 
                                Density, 
                                dplyr::num_range("",
                                          1:(ncol(.)-1))
                                ) %>%
                  ggplot2::ggplot(ggplot2::aes(x = `Years BP`,
                                      y = Density,
                                      colour = Period)) +
                  ggplot2::geom_line() +
                  ggplot2::xlim(6000,0) +
                  ggplot2::ggtitle(site)
                print(g)
                dev.off()
              }
            })

# Summing across all distributions yields the net distribution
cairo_pdf(filename = "./figures/all_sites_density.pdf")
g <- densities %$%
  Density %>%
  do.call(cbind,.) %>%
  {rowSums(.)/ncol(.)} %>%
  magrittr::multiply_by(20) %>%
  tibble::tibble(`Years BP` = marcott2013$YearBP,
                 Density = .) %>%
  ggplot2::ggplot(ggplot2::aes(x = `Years BP`,
                               y = Density)) +
  ggplot2::geom_line() +
  ggplot2::xlim(6000,0)
print(g)
dev.off()


# Create a spatial object of the sites
sites <- chronometric_data %>%
  dplyr::mutate(foxtail_millet = ifelse(is.na(`Foxtail millet`), FALSE, TRUE),
         broomcorn_millet = ifelse(is.na(`Broomcorn millet`), FALSE, TRUE),
         wheat = ifelse(is.na(Wheat), FALSE, TRUE),
         barley = ifelse(is.na(Barley), FALSE, TRUE),
         buckwheat = ifelse(is.na(Buckwheat), FALSE, TRUE)) %>%
  dplyr::select(Site,
                Period,
                Longitude,
                Latitude,
                `14C date on cereal?`,
                foxtail_millet,
                broomcorn_millet,
                wheat,
                barley,
                buckwheat) %>%
  dplyr::ungroup() %>%
  dplyr::distinct() %>%
  tidyr::gather(Crop, Present, -Site, -Period, -Longitude, -Latitude, -`14C date on cereal?`) %>%
  dplyr::filter(Present) %>%
  dplyr::select(-Present) %>%
  dplyr::distinct() %>%
  dplyr::arrange(Site, Period) %>%
  sf::st_as_sf(coords = c("Longitude", "Latitude")) %>%
  sf::st_set_crs("+proj=longlat")

# Map the sites
cairo_pdf("./figures/crop_map.pdf", width = 7.2, height = 7)
print(sites %>%
        dplyr::filter(Crop != "buckwheat") %>%
        dplyr::mutate(Crop = dplyr::recode_factor(Crop,
                                                  foxtail_millet = "Foxtail millet",
                                                  broomcorn_millet = "Broomcorn millet",
                                                  wheat = "Wheat",
                                                  barley = "Barley")) %>%
        ggplot2::ggplot() +
        ggplot2::geom_sf(data = countries,
                         inherit.aes = FALSE,
                         show.legend = FALSE) +
        ggplot2::geom_sf(ggplot2::aes(colour = Crop,
                                      shape = `14C date on cereal?`),
                         show.legend = "point",
                         inherit.aes = FALSE,
                size = 1) +
            ggplot2::scale_x_continuous(expand = c(0, 0)) +
    ggplot2::scale_y_continuous(expand = c(0, 0)) +
        ggplot2::theme_minimal(base_size = 7) +
      ggplot2::guides(colour=FALSE) +
        # ggplot2::theme(legend.position="none") +
        ggplot2::facet_wrap( ~ Crop, ncol = 2))
dev.off()

# A function to extract niches for each crop
extract_niches <- function(x){
  out_niche <- raster::brick(paste0("./data/derived_data/recons/All_",x$Crop[[1]],"_Z.nc")) %>%
    raster:::readAll() %>%
    raster::extract(x %>%
                      as("Spatial")) %>%
    split(row(.))
  x %<>%
    set_class(c("tbl_df", "tbl", "data.frame")) %>%
    dplyr::mutate(Niche = out_niche) %>%
    sf::st_as_sf()
  return(x)
}

# Extract niches for each crop
niches <- sites %>%
  split(as.factor(sites$Crop)) %>%
  purrr::map(extract_niches) %>%
  purrr::map(~ set_class(., c("tbl_df", "tbl", "data.frame"))) %>%
  do.call(what = rbind, args = .) %>%
  sf::st_as_sf()

# A function to extract the 95% confidence interval of a distribution
get_CI <- function(dens){
  dens[is.na(dens)] <- 0
  cum_dens <- dens %>%
    cumsum() %>%
    magrittr::divide_by(sum(dens, na.rm = T))
  lower <- which(cum_dens >= 0.025)[1]
  mid <- which(cum_dens >= 0.5)[1]
  upper <- which(cum_dens >= 0.975)[1]
  return(list(Density = dens, Median = mid, CI = c(lower = lower, upper = upper)))
}

# A function to calculate local niches
local_niche <- function(niche, dens){
  if(is.na(dens$CI[["lower"]]) | is.na(dens$CI[["upper"]])) return(NULL)
  out_niche <- list()
  out_niche$Niche <- rep(NA, length(niche))
  out_niche$Niche[dens$CI[["lower"]]:dens$CI[["upper"]]] <- niche[dens$CI[["lower"]]:dens$CI[["upper"]]]
  out_niche$Niche <- out_niche$Niche / 100 # onvert to probability
  out_niche$Median <- quantile(out_niche$Niche, probs = 0.5, na.rm = TRUE)
  out_niche$CI <- c(quantile(out_niche$Niche, probs = 0.025, na.rm = TRUE),
                    quantile(out_niche$Niche, probs = 0.975, na.rm = TRUE))
  names(out_niche$CI) <- c("lower","upper")
  return(out_niche)
}

# Get the "Local" niche densities, by multiplying the site occupation probability densities
# by the crop niche probabilities (summing will get the average)
# Join the niche and density tables
niche_densities <- niches %>%
  set_class(c("tbl_df", "tbl", "data.frame")) %>%
  dplyr::left_join(densities, by = c("Site", "Period")) %>%
  dplyr::select(Site:Niche, Density) %>%
  # Get local densities
  dplyr::mutate(Density = purrr::map(Density, get_CI),
                Niche = purrr::map2(Niche, Density, local_niche)
  )

# Create biplots of each crop/site
purrr::walk(unique(niche_densities$Crop),
            function(crop){
              
              cairo_pdf(paste0("./figures/",crop,"_crossplot.pdf"))
              p <- niche_densities %>%
                dplyr::filter(Crop == crop) %>%
                dplyr::filter(!purrr::map_lgl(Niche, is.null)) %>%
                dplyr::mutate(Density_Median = marcott2013$YearBP[purrr::map_int(Density, "Median")],
                              Density_Lower = marcott2013$YearBP[purrr::map(Density, "CI") %>%
                                                                   purrr::map_dbl("lower")],
                              Density_Upper = marcott2013$YearBP[purrr::map(Density, "CI") %>%
                                                                   purrr::map_dbl("upper")],
                              Crop_Median = purrr::map_dbl(Niche, "Median"),
                              Crop_Lower = purrr::map(Niche, "CI") %>%
                                purrr::map_dbl("lower"),
                              Crop_Upper = purrr::map(Niche, "CI") %>%
                                purrr::map_dbl("upper")) %>%
                ggplot2::ggplot(ggplot2::aes(x = Density_Median, 
                                             y = Crop_Median, 
                                             label = Site)) +
                ggplot2::geom_point(na.rm = TRUE) +
                ggplot2::geom_errorbarh(ggplot2::aes(xmin = Density_Lower,
                                   xmax = Density_Upper),
                               na.rm = TRUE) +
                ggplot2::geom_errorbar(ggplot2::aes(ymin = Crop_Lower,
                                  ymax = Crop_Upper),
                              na.rm = TRUE) +
                ggplot2::xlim(6000,0) +
                ggplot2::ylim(0,1) +
                ggplot2::xlab("Years BP") +
                ggplot2::ylab(stringr::str_c("Probability of Being in the ",crop," Niche"))
              print(p)
              dev.off()
              
            })

p <- niche_densities %>%
  dplyr::mutate(`Site, Period` = stringr::str_c(Site,ifelse(is.na(Period),"",stringr::str_c(", ",Period)))) %>%
  dplyr::filter(!purrr::map_lgl(Niche, is.null),
                Crop != "buckwheat") %>%
  dplyr::mutate(Crop = dplyr::recode_factor(Crop,
                                            foxtail_millet = "Foxtail millet",
                                            broomcorn_millet = "Broomcorn millet",
                                            wheat = "Wheat",
                                            barley = "Barley")) %>%
  dplyr::mutate(Density_Median = marcott2013$YearBP[purrr::map_int(Density, "Median")],
                Density_Lower = marcott2013$YearBP[purrr::map(Density, "CI") %>%
                                                     purrr::map_dbl("lower")],
                Density_Upper = marcott2013$YearBP[purrr::map(Density, "CI") %>%
                                                     purrr::map_dbl("upper")],
                Crop_Median = purrr::map_dbl(Niche, "Median"),
                Crop_Lower = purrr::map(Niche, "CI") %>%
                  purrr::map_dbl("lower"),
                Crop_Upper = purrr::map(Niche, "CI") %>%
                  purrr::map_dbl("upper")) %>%
  ggplot2::ggplot(ggplot2::aes(x = Density_Median,
                      y = Crop_Median,
                      colour = Crop,
                      label = `Site, Period`)) +
  ggplot2::geom_point(na.rm = TRUE) +
  ggplot2::geom_errorbarh(ggplot2::aes(xmin = Density_Lower,
                     xmax = Density_Upper),
                 na.rm = TRUE) +
  ggplot2::geom_errorbar(ggplot2::aes(ymin = Crop_Lower,
                    ymax = Crop_Upper),
                na.rm = TRUE) +
  ggplot2::xlim(6000,0) +
  ggplot2::ylim(0,1) +
  ggplot2::xlab("Years BP") +
  ggplot2::ylab(stringr::str_c("Probability of Being in the Niche"))

cairo_pdf("./figures/All_crossplot.pdf", width = 7.2, height = 5.91)
print(p +
        ggplot2::theme_minimal(base_size = 7) +
        ggplot2::theme(legend.position="none") +
        ggplot2::facet_wrap( ~ Crop, ncol=2))
dev.off()

pp <- plotly::ggplotly(tooltip = c("label"))
htmlwidgets::saveWidget(widget = plotly::as_widget(pp),
                        file = "All_crossplot.html")
file.copy("All_crossplot.html",
          to = "./figures/All_crossplot.html",
          overwrite = TRUE)
unlink("All_crossplot.html")

# Write out a table
niche_densities_extract <- niche_densities %>%
  dplyr::filter(!purrr::map_lgl(Niche, is.null)) %>%
  dplyr::mutate(`Age median (BP)` = marcott2013$YearBP[purrr::map_int(Density, "Median")],
                `Age lower CI (BP)` = marcott2013$YearBP[purrr::map(Density, "CI") %>%
                                                           purrr::map_dbl("lower")],
                `Age upper CI (BP)` = marcott2013$YearBP[purrr::map(Density, "CI") %>%
                                                           purrr::map_dbl("upper")],
                `Niche probability median` = purrr::map_dbl(Niche, "Median"),
                `Niche probability lower CI` = purrr::map(Niche, "CI") %>%
                  purrr::map_dbl("lower"),
                `Niche probability upper CI` = purrr::map(Niche, "CI") %>%
                  purrr::map_dbl("upper")) %>%
  dplyr::select(-Niche:-Density) %>%
  dplyr::distinct() %>%
  dplyr::mutate(Crop = dplyr::recode_factor(Crop,
                                            foxtail_millet = "Foxtail millet",
                                            broomcorn_millet = "Broomcorn millet",
                                            wheat = "Wheat",
                                            barley = "Barley",
                                            buckwheat = "Buckwheat")) %>%
  dplyr::arrange(Site, Period, Crop) %T>%
  readr::write_csv("./data/derived_data/age_niche_estimates.csv")

# Plot relationship between number of crops and age
cairo_pdf("./figures/Age_counts.pdf",
          width = 3.5,
          height = 2)
print({
  niche_densities_extract %>%
    dplyr::filter(Crop != "Buckwheat") %>%
    dplyr::select(-Crop) %>%
    dplyr::group_by(Site, Period) %>%
    dplyr::summarise_all(.funs = mean) %>%
    dplyr::left_join(niche_densities_extract %>%
                       dplyr::group_by(Site, Period) %>%
                       dplyr::count(),
                     by = c("Site", "Period")) %>%
    dplyr::rename(`Number of crops` = n) %>%
    ggplot2::ggplot() +
    ggplot2::geom_point(ggplot2::aes(x = `Number of crops`,
                   y = `Niche probability median`),
               size = 1) +
    ggplot2::geom_smooth(ggplot2::aes(x = `Number of crops`,
                    y = `Niche probability median`),
                method = "lm")+
    ggplot2::theme_minimal(base_size = 7)
})
dev.off()

```

## Generate niche videos
```{r niche-videos}

## Plotting crop niche with associated sites
# create the cluster for parallel computation
message("Plotting crop niche reconstructions")
time_check <-  Sys.time()

# Combine the sites with the density data
site_densities <- niche_densities %>%
  dplyr::filter(!purrr::map_lgl(Niche, is.null)) %>%
  dplyr::mutate(Density_Lower = marcott2013$YearBP[purrr::map(Density, "CI") %>%
                                                     purrr::map_dbl("lower")],
                Density_Upper = marcott2013$YearBP[purrr::map(Density, "CI") %>%
                                                     purrr::map_dbl("upper")]) %>%
  dplyr::select(-Density) %>%
  dplyr::filter(!is.na(Density_Lower)) %>%
  dplyr::left_join(sites, by = c("Site", "Period", "Crop")) %>%
  dplyr::mutate(Niche = purrr::map(Niche, function(x){
    x$Niche <-
      tibble::tibble(`Year BP` = marcott2013$YearBP, Niche = x$Niche)
    return(x)
  }))

crops <- crop_GDD %>%
  dplyr::filter(crop %in% site_densities$Crop) %>%
  dplyr::select(crop_long, crop) %>%
  dplyr::distinct()

message("Generating niche videos.")
dir.create("./figures/crop_niches",
           recursive = TRUE,
           showWarnings = TRUE)

for(n in 1:nrow(crops)){
  
  crop <- crops[n,]$crop
  
  title <- stringr::str_c(crops[n,]$crop_long)
  
  if(file.exists(paste0("./figures/crop_niches/All_",crop,".pdf")) & file.exists(paste0("./figures/crop_niches/All_",crop,".mp4")))
    next
  
  rast <- raster::brick(paste0("./data/derived_data/recons/All_",crop,"_Z.nc")) %>%
    magrittr::extract2(which(.@z$`Years BP` > 1000)) %>%
    raster:::readAll() %>%
    magrittr::divide_by(100) %>%
    magrittr::extract2(raster::nlayers(.):1)
  
  rast.lower <- raster::brick(paste0("./data/derived_data/recons/All_",crop,"_Z_Lower.nc")) %>%
    magrittr::extract2(which(.@z$`Years BP` > 1000)) %>%
    raster:::readAll() %>%
    magrittr::divide_by(100) %>%
    magrittr::extract2(raster::nlayers(.):1)
  
  rast.upper <- raster::brick(paste0("./data/derived_data/recons/All_",crop,"_Z_Upper.nc")) %>%
    magrittr::extract2(which(.@z$`Years BP` > 1000)) %>%
    raster:::readAll() %>%
    magrittr::divide_by(100) %>%
    magrittr::extract2(raster::nlayers(.):1)
  
  years <- rast %>%
    names() %>%
    gsub(pattern = "X",
         replacement = "",
         x = .) %>%
    as.numeric()
  
                                 breaks <- seq(0, 1, 0.1)
                                 
                                 pal <- (RColorBrewer::brewer.pal(10, "Spectral") %>%
                                           rev() %>%
                                           colorRampPalette(.))(length(breaks) - 1)
  
  if(!file.exists(paste0("./figures/crop_niches/All_",crop,".pdf")))
    guedesbocinsky2018:::space_time_plot(the_brick = rast,
                    the_brick_lower = rast.lower,
                    the_brick_upper = rast.upper,
                    out_file = paste0("./figures/crop_niches/All_",crop,".pdf"),
                    title = title,
                    time = years,
                    timelim = c(max(years),min(years)),
                    timeaxis =  seq(from = max(years)-500,
                                    to = min(years),
                                    by = -500),
                    timelab = "Years BP",
                    zbreaks = breaks,
                    zlab = "Probability of being in niche",
                    zaxis = seq(0,1,0.1),
                    zcolors = pal
    )
  
  
  if(!file.exists(paste0("./figures/crop_niches/All_",crop,".mp4"))){
    # A function to extract site locations for a given year and crop, and plot them
    sites_plot <- function(years = NULL, crops = NULL, scale = scales::area_pal(c(0,1))){
      x_plot <- site_densities
      year_idx <- which(marcott2013$YearBP == years)
      
      if(!is.null(crops)){
        x_plot %<>%
          dplyr::filter(Crop %in% crops)
      }
      
      cexs <- purrr::map(x_plot$Niche,c("Niche","Niche")) %>%
        purrr::map(year_idx) %>%
        unlist() %>%
        scale()
      
      if(cexs %>%
         is.na() %>%
         all()) return() #Don't plot if no sites during this period
      
      x_plot %<>%
        dplyr::filter(!is.na(cexs))
      
      cexs <- cexs[!is.na(cexs)]
      
      x_plot %$%
        plot(geometry,
             cex = cexs,
             pch = 1,
             lwd = 3,
             col = "white",
             add = T)
      x_plot %$%
        plot(geometry,
             cex = cexs,
             pch = 1,
             lwd = 1.5,
             col = "black",
             add = T)
    }
    
    sites_legend <- function(){
      legend("bottomright",
             title = "Site probability \nof being in niche",
             legend = seq(0,1,0.2),
             pch = 1,
             pt.lwd = 1.5,
             col = "black",
             pt.cex = scales::area_pal(c(0.5,3))(seq(0,1,0.2)),
             bty = "n",
             y.intersp = 1.5,
             cex = 0.8,
             text.font = 2
      )
    }
    
    guedesbocinsky2018:::space_time_video(the_brick = rast,
                     the_brick_lower = rast.lower,
                     the_brick_upper = rast.upper,
                     out_file = paste0("./figures/crop_niches/All_",crop,".mp4"),
                     title = title,
                     time = years,
                     timelim = c(max(years),min(years)),
                     timeaxis =  seq(from = max(years)-500,
                                     to = min(years),
                                     by = -500),
                     timelab = "Years BP",
                     zbreaks = breaks,
                     zlab = "Probability of being in niche",
                     zaxis = seq(0,1,0.1),
                     zcolors = pal,
                     extra_plot_fun = purrr::partial(sites_plot,
                                                     crops = crop,
                                                     scale = scales::area_pal(c(0.5,3))),
                     extra_legend_fun = sites_legend
    )
    
  }
}

# Create a static plot for paper publication
# A function to extract data from a crop raster brick
tidyCrop <- function(x, years){
  x %>%
    paste0("./data/derived_data/recons/All_",.,"_Z.nc") %>%
    raster::brick() %>%
    magrittr::extract2(stringr::str_c("X",years)) %>%
    raster:::readAll() %>%
    magrittr::divide_by(100) %>%
    as("SpatialPixelsDataFrame") %>%
    tibble::as_tibble() %>%
    tidyr::gather(Year, Niche, -x:-y) %>%
    dplyr::rename(Longitude = x,
                  Latitude = y) %>%
    dplyr::mutate(Year = gsub(pattern = "X",
                              replacement = "",
                              x = Year),
                  Year = factor(Year, levels = years),
                  Year = forcats::fct_relabel(Year, function(x){stringr::str_c(x," cal. BP")}),
                  Crop = x)
}

breaks <- seq(0, 1, 0.1)

pal <- (RColorBrewer::brewer.pal(10, "Spectral") %>%
          rev() %>%
          colorRampPalette(.))(length(breaks) - 1)

# A function to create a plot of years and crops
facet_niche <- function(crops, years){
  these_sites <- years %>%
    purrr::map(function(year){
      site_densities %>%
        dplyr::mutate(Year = year) %>%
        dplyr::filter(Density_Lower <= Year & Density_Upper >= Year,
                      Crop %in% crops) %>%
        dplyr::mutate(Longitude = sf::st_coordinates(geometry)[,"X"],
                      Latitude = sf::st_coordinates(geometry)[,"Y"]) %>%
        dplyr::select(Site, Longitude, Latitude, Crop, Year)
    }) %>%
    dplyr::bind_rows() %>%
    dplyr::mutate(Year = factor(Year, levels = years),
                  Year = forcats::fct_relabel(Year, function(x){stringr::str_c(x," cal. BP")}),
                  Crop = dplyr::recode_factor(Crop,
                                              wheat = "Wheat",
                                              barley = "Barley",
                                              broomcorn_millet = "Broomcorn millet",
                                              foxtail_millet = "Foxtail millet"))
  
  these_rasters <- crops %>%
    purrr::map(tidyCrop, years = years) %>%
    dplyr::bind_rows() %>%
    dplyr::mutate(Crop = dplyr::recode_factor(Crop,
                                              wheat = "Wheat",
                                              barley = "Barley",
                                              broomcorn_millet = "Broomcorn millet",
                                              foxtail_millet = "Foxtail millet"))
  
  p <- these_rasters %>%
    ggplot2::ggplot() +
    ggplot2::geom_raster(mapping = ggplot2::aes(x = Longitude,
                                                y = Latitude,
                                                fill = Niche)) +
    ggplot2::scale_fill_gradientn(colours = pal,
                                  limits=c(0, 1),
                                  name = "Probability of\nbeing in niche") +
    ggplot2::geom_point(data = these_sites,
                        mapping = ggplot2::aes(x = Longitude,
                                               y = Latitude),
                        size = 1) +
    ggplot2::coord_quickmap() +
    ggplot2::facet_grid(Crop ~ Year,
                        switch = "y")
  
  return(p)
}

cairo_pdf("./figures/facet_niche.pdf", width = 7.2, height = 8.25)
print({
  facet_niche(crops = c("wheat", "barley", "broomcorn_millet", "foxtail_millet"),
              years = c(4030, 3550, 1690)) +
    ggplot2::scale_y_continuous(position = "right") +
    # xlab("") +
    # ylab("") +
    ggplot2::theme_minimal(base_size = 7) +
    ggplot2::theme(strip.text.x = ggplot2::element_text(size = 8),
          strip.text.y = ggplot2::element_text(size = 8))
})
dev.off()

message("Plotting of crop niche reconstructions complete: ", capture.output(Sys.time() - time_check))

```

<!-- The following line inserts a page break when the output is MS Word. For page breaks in PDF, use \newpage on its own line.  -->
##### pagebreak

# References 
<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->
<div id="refs"></div>

##### pagebreak

### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies: 

```{r colophon, cache = FALSE}
# which R packages and versions?
devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? You may need to change the path value
# if your Rmd is not in analysis/paper/
git2r::repository("..")
```
